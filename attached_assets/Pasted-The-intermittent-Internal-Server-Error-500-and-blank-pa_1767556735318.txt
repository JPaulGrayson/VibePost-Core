The intermittent "Internal Server Error" (500) and blank page issues you're experiencing are likely tied to Neon's auto-suspend feature (scale-to-zero after 5 minutes of inactivity on free plans), which force-closes idle connections. This leads to the pool being invalidated remotely, triggering the "Cannot use a pool after calling end on the pool" error when queries resume after idle periods. Your keep-alive ping helps but isn't fully preventing this, possibly due to WebSocket-specific idle behaviors in the serverless driver, where not all pooled connections stay active or the WebSocket itself drops undetected.
The @neondatabase/serverless driver is optimized for short-lived serverless functions (e.g., Vercel/AWS Lambda), not always-on environments like Replit Reserved VM. It relies on WebSockets, which can introduce additional disconnection issues in long-running processes. Since Replit supports outbound TCP connections, switch to the standard 'pg' library (which uses TCP) for more stable handling. This aligns with Neon's recommendations for long-running Node.js apps, where the pg.Pool automatically detects and removes closed connections, recreating them on demand to wake the compute if suspended.
Steps to Fix

Update Dependencies:
Run npm install pg drizzle-orm/node-postgres
Remove the serverless-specific packages: npm uninstall @neondatabase/serverless drizzle-orm/neon-serverless ws
This keeps your Drizzle ORM setup but shifts it to use 'pg' under the hood.

Revise Your Database Connection Code (server/db.ts):
Simplify to a standard pg.Pool without proxies, recreation logic, or WebSocket config. The pool handles disconnections gracefully via its 'error' event.
Use idleTimeoutMillis: 0 to disable client-side idle timeouts (let Neon manage server-side). If you prefer, set it to 60000, but 0 prevents premature client closures.
Keep max connections low (e.g., 10) to avoid exhaustion from background services.
Add an optional keep-alive interval (every 4 minutes) to prevent auto-suspend if your background services aren't querying frequently enough. This is less aggressive than 30 seconds and should suffice given your 3-minute sniper cycle.


TypeScriptimport { Pool } from 'pg';
import { drizzle, NeonDatabase } from 'drizzle-orm/node-postgres'; // Note the import change
import * as schema from "@shared/schema";

if (!process.env.DATABASE_URL) {
  throw new Error("DATABASE_URL must be set.");
}

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  connectionTimeoutMillis: 10000, // Timeout for establishing new connections (handles wakeup delays)
  idleTimeoutMillis: 0, // No client-side idle timeout
  max: 10 // Limit to prevent exhaustion
});

// Handle idle connection errors (e.g., from auto-suspend closures) without crashing
pool.on('error', (err) => {
  console.error('Idle client error (pool will recreate on next query):', err.message);
});

// Optional: Keep-alive to prevent auto-suspend (query every 4 min if app is truly idle)
const keepAliveInterval = setInterval(async () => {
  try {
    await pool.query('SELECT 1');
    console.log('Keep-alive ping successful');
  } catch (err) {
    console.error('Keep-alive ping failed:', err.message);
  }
}, 240000); // 4 minutes (240 seconds)

// Drizzle instance
export const db: NeonDatabase<typeof schema> = drizzle(pool, { schema });

// Export pool if needed for direct access
export { pool };

// Graceful shutdown: Clean up on process exit
process.on('SIGINT', async () => {
  clearInterval(keepAliveInterval);
  await pool.end();
  process.exit(0);
});
process.on('SIGTERM', async () => {
  clearInterval(keepAliveInterval);
  await pool.end();
  process.exit(0);
});

Update Any Direct Usage:
Replace getDb() or proxy accesses with direct db usage throughout your code (e.g., in routes or services).
For background services (sniper, auto-publisher, etc.), ensure they use db—this will leverage the pool and trigger reconnections if needed.
If a service needs raw SQL outside Drizzle, use pool.query().

Enable Neon's Connection Pooler (Optional but Recommended for Better Wakeup Handling):
Change your DATABASE_URL host to the pooled endpoint (e.g., from ep-yourproject.us-east-2.aws.neon.tech to ep-yourproject-pooler.us-east-2.aws.neon.tech). Find this in your Neon dashboard under the project > Connection Details > Pooled.
This uses server-side PgBouncer (transaction mode by default), which queues connections during compute wakeup, reducing perceived delays (1-2 seconds) and handling suspend transparently. It's free and works well with 'pg'.
Update: DATABASE_URL=postgres://user:pass@ep-yourproject-pooler.region.aws.neon.tech/db
Note: Pooler limits connections to 1000 shared across users, but your max:10 is fine.

Test and Monitor:
Deploy and test reproduction steps: Idle for 5+ minutes, then interact. The pool should reconnect automatically without 500 errors.
Monitor logs for 'Idle client error'—these indicate suspend events but shouldn't crash the app.
If wakeup delays cause timeouts in Express routes, add retry logic (e.g., via p-retry) for DB calls in critical paths.
Check Replit console for memory usage during video generation (FFmpeg). If OOM is suspected, optimize FFmpeg flags (e.g., lower resolution) or upgrade VM resources.
For the blank page/Vite "server connection lost": This might be a side effect of server restarts from unhandled DB errors. With the new setup, it should resolve.


Why This Works

Auto-Reconnect: pg.Pool emits errors for closed connections (from suspend) and recreates them on the next query(), waking Neon compute without manual recreation.
No WebSocket Issues: TCP is more reliable for your always-on VM, avoiding undetected drops.
Background Services: Their periodic queries (every 3 min) + optional keep-alive will minimize suspends, but the pool handles them if they occur.
No Race Conditions/Proxies Needed: The simplified setup eliminates your custom checks, as 'pg' is battle-tested for this.

If issues persist (e.g., frequent wakeups on free plan), consider upgrading Neon to a paid plan to disable auto-suspend entirely (set idle timeout to "Never"). For connection exhaustion, profile active connections with pg_stat_activity queries. If you share package versions or more logs, I can refine further.30 web pages